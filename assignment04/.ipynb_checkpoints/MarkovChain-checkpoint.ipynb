{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:** Learn how to build Markov Chains from n-grams and generate new sequences from the Markov Chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import types\n",
    "from itertools import islice\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about the background information related to n-grams [here](https://en.wikipedia.org/wiki/N-gram). Write a function, `build_ngrams`, that returns n-grams from an input sequene (iterator). Try to do this without concrete lists. The `islice` function may be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "91e898737a49eccfcddb1b81a5dc0081",
     "grade": false,
     "grade_id": "markovchaina",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_ngrams(itr, n=2):\n",
    "    \"\"\"Return the sequence of n-grams from the source iterator.\"\"\"\n",
    "    return zip(*[islice(itr, i, len(itr)) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d5e2a40b50b1497822c07250c20e79fb",
     "grade": true,
     "grade_id": "markovchainb",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "a = build_ngrams(range(10), n=2)\n",
    "assert hasattr(a, '__iter__') and not isinstance(a, list)\n",
    "al = list(a)\n",
    "assert al == [(i,i+1) for i in range(9)]\n",
    "\n",
    "b = build_ngrams(range(10), n=5)\n",
    "assert hasattr(b, '__iter__') and not isinstance(b, list)\n",
    "bl = list(b)\n",
    "assert bl == [(i,i+1,i+2,i+3,i+4) for i in range(6)]\n",
    "\n",
    "assert list(build_ngrams('one two three four five six seven'.split(' '), n=5)) == \\\n",
    "    [('one','two','three','four','five'),\n",
    "     ('two','three','four','five','six'),\n",
    "     ('three','four','five','six','seven')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about the background of Markov Chains [here](https://en.wikipedia.org/wiki/Markov_chain). Write a function `build_chain`, that returns a Markov Chain for a sequence of n-grams. This function should return a `dict` with:\n",
    "\n",
    "* The keys will be the source node in the Markov Chain, which is the first `n-1` elements in each n-gram, as a `tuple`.\n",
    "* The values will be a *list* of possible targets in the Markov Chain. As you find new values for a single key, you will need to append to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "81db0d592629e73d52ebe4212ed7873f",
     "grade": false,
     "grade_id": "markovchainc",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_chain(ngrams, chain=None):\n",
    "    \"\"\"Build a Markov chain out of an iterator of n-grams.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ngrams: list of n-tuples\n",
    "        A list of n-grams as tuples, where the first n-1 elements are the source node\n",
    "        in the Markov chain ahd the last element is the target node in the Markov chain.\n",
    "    chain: dict or None\n",
    "        An existing Markov chain to add ngrams to or None for a new chain.\n",
    "    \"\"\"\n",
    "    ngram_list = list(ngrams)\n",
    "    ngram_len = len(ngram_list[0])\n",
    "    \n",
    "    if chain is None:\n",
    "        chain = {}\n",
    "    \n",
    "    for ngram in ngram_list:\n",
    "        source_node = ngram[:ngram_len - 1]\n",
    "        target_node = ngram[ngram_len - 1]\n",
    "        \n",
    "        if source_node not in chain:\n",
    "            chain[source_node] = []\n",
    "        \n",
    "        chain[source_node].append(target_node)\n",
    "        \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cdc2c5a4d76be2333c46c36d3434a42b",
     "grade": true,
     "grade_id": "markovchaind",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "seq1 = [random.randint(0,10) for i in range(200)]\n",
    "chain = build_chain(build_ngrams(seq1, n=3))\n",
    "seq2 = [random.randint(0,10) for i in range(200)]\n",
    "chain = build_chain(build_ngrams(seq2, n=3), chain=chain)\n",
    "assert chain[(0,0)]==[7, 10, 0, 3, 4]\n",
    "assert chain[(4,2)]==[1, 3, 8, 3, 7, 1, 10, 2, 8]\n",
    "assert len(chain.keys())==111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, `generate_sequence`, that can generate new sequences of length `m` from a trained Markov Chain (in the `dict` format described above). For the initial part of the sequence, randomly choose one of the keys in the Markov Chain `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c6a6198595980de73f730a79952898e9",
     "grade": false,
     "grade_id": "markovchaine",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sequence(chain, m):\n",
    "    \"\"\"Generate a new sequence of length m from a Markov chain.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    chain : dict\n",
    "        A dict where the keys are the source node of the Markov chain steps and\n",
    "        the values are a list of possible targets.\n",
    "    m : int\n",
    "        The length of the sequence to generate.\n",
    "    \"\"\"\n",
    "    seq = []\n",
    "    chain_keys = list(chain.keys())\n",
    "    chain_key_ndx = random.randint(0, len(chain_keys) - 1)\n",
    "    next_key = chain_keys[chain_key_ndx]\n",
    "    \n",
    "    # add initial key to sequence\n",
    "    for i in next_key:\n",
    "        seq.append(i)\n",
    "        \n",
    "    # while we need to add to the sequence\n",
    "    while len(seq) < m:\n",
    "        #grab potential target nodes\n",
    "        targets = chain[next_key]\n",
    "        # randomly choose a target node\n",
    "        target = random.choice(targets)\n",
    "        # append target to generated sequence\n",
    "        seq.append(target)\n",
    "        \n",
    "        # generate new key from existing key and target\n",
    "        next_key = list(next_key[1:])\n",
    "        next_key.append(target)\n",
    "        next_key = tuple(next_key)\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "faa5f8bc8e07683354c2b6acb23d4f45",
     "grade": true,
     "grade_id": "markovchainf",
     "locked": true,
     "points": 4,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "seq3 = [random.randint(0,10) for i in range(200)]\n",
    "chain2 = build_chain(build_ngrams(seq1, n=3))\n",
    "assert list(generate_sequence(chain2, 10))==[8, 0, 1, 8, 10, 6, 8, 4, 8, 9]\n",
    "chain3 = build_chain(build_ngrams(seq1, n=5))\n",
    "assert list(generate_sequence(chain3, 10))==[4, 1, 8, 5, 8, 3, 9, 8, 9, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the web to find lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the exercise, you will need to find lyrics from one of your favorite bands, and use the [requests](http://docs.python-requests.org/en/latest/) and [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) packages to scrape the lyrics from a website. Some guidance:\n",
    "\n",
    "1. The more songs the better (many dozens).\n",
    "2. No hand downloading or editing of the files, you must do everything from code.\n",
    "3. Save all of the lyrics in a single text file in this directory.\n",
    "\n",
    "I provide an example here of doing this for all of U2's lyrics. You will have to modify this code significantly for the band of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get the page that has an index of all the lyrics and create a list of the URLs of those pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lyric_urls():\n",
    "    index = requests.get(\"http://www.metrolyrics.com/eminem-lyrics.html\")\n",
    "    soup = BeautifulSoup(index.text, 'html.parser')    \n",
    "    lyric_paths = [link.get('href') for link in\n",
    "                   soup.find_all('table', class_='songs-table')[0].find_all('a')]\n",
    "    \n",
    "    return lyric_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyric_urls = get_lyric_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function that takes the URL of a single lyric page and scrapes the actual lyric as text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lyric(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    html_lyrics = soup.find_all('div', class_='lyrics-body')[0].find_all('p')\n",
    "    lyrics = []\n",
    "    \n",
    "    for l in html_lyrics:\n",
    "        lyric = l.getText()\n",
    "        lyric = lyric.replace(\"\\n\", \" \")        \n",
    "        lyrics.append(lyric)\n",
    "        \n",
    "    return \" \".join(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets all of the lyrics. Note the `time.sleep(1.0)`. When scraping websites, it is often important to throttle your requests so as to not get banned from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_all_lyrics(lyric_urls):\n",
    "    for url in lyric_urls:\n",
    "        time.sleep(1.0)\n",
    "        yield get_lyric(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics = get_all_lyrics(lyric_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save all the lyrics to a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('all_eminem_lyrics.txt', 'w') as f:\n",
    "    for lyric in lyrics:\n",
    "        f.write(lyric.replace('\\r\\n', '\\n'))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave the following cell to grade your code for this section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f889417210aa361e68fb66b457e7c256",
     "grade": true,
     "grade_id": "markovchaing",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new lyrics with the Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the fun part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simple function for tokenizing the lyrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PUNCTUATION = '`~!@#$%^&*()_-+={[}]|\\:;\"<,>.?/}\\t\\n'\n",
    "\n",
    "def remove_punctuation(words, punctuation=PUNCTUATION):\n",
    "    \"\"\"Remove punctuation from an iterator of words, yielding the results.\"\"\"\n",
    "    for word in words:\n",
    "        word = word.strip(punctuation)\n",
    "        split_word = word.replace(\"-\", \" \").split()\n",
    "        \n",
    "        for word in split_word:\n",
    "            if word != '':\n",
    "                yield word\n",
    "                \n",
    "def lower_words(words):\n",
    "    \"\"\"Make each word in an iterator lowercase.\"\"\"\n",
    "    for word in words:\n",
    "        yield word.lower()\n",
    "\n",
    "def tokenize_line(line, punctuation=PUNCTUATION):\n",
    "    \"\"\"Split a string into a list of words, removing punctuation and stop words.\"\"\"\n",
    "    for word in list(lower_words(remove_punctuation(line.split()))):\n",
    "        yield word\n",
    "\n",
    "def tokenize_lines(lines, punctuation=PUNCTUATION):\n",
    "    \"\"\"Tokenize an iterator of lines, yielding the tokens.\"\"\"\n",
    "    for line in lines:\n",
    "        for word in list(tokenize_line(line, punctuation)):\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in your lyric file, tokenize the text (no stop words!) and generate new song lyrics. Some things to think about:\n",
    "\n",
    "* This will work best if you generate new lines of text of some finite length (10-30 words).\n",
    "* Use `textwrap.wrap` to format these lines and separate them using newlines.\n",
    "* To get interesting results, you may need to run it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dcee0be047fd121f6d9718b809f5538a",
     "grade": true,
     "grade_id": "markovchainh",
     "locked": false,
     "points": 4,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chain = {}\n",
    "\n",
    "with open(\"all_eminem_lyrics.txt\") as f:\n",
    "    for line in f:\n",
    "        seq = list(tokenize_line(line))\n",
    "        ngram = build_ngrams(seq, n=3)\n",
    "        chain = build_chain(ngram, chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that shiddit you should probably run a secret passage way around \n",
      "sink and you will love it when you feel like i \n",
      "leave ma let me see they tried to argue it was \n",
      "father to show that when my days of serial murder man \n",
      "write back see i'm just saying i gave up is using \n",
      "and sending it to the tale i'm about to lose him \n",
      "sucka this shit ain't that hard that hard that hard that \n",
      "harder to hold onto it 'cause the thrill's cheap said you \n",
      "and ja beef from happening me and i'm just tryin' to \n",
      "you're in each others throats especially when dad he fucked us \n",
      "bitch you're coming with me shit look at shit through each \n",
      "you've had it up to the finish wit' me valium spinach \n",
      "about coke no more reason to cry cause you're my amy \n",
      "again then when i close my eyes through the ringer but \n",
      "allright lets pretend like they got something to say unless it \n",
      "a food stamp skipped to the pain i've caused but what \n",
      "mouth see they tried to say it in her throat cut \n",
      "better shut your lying mouth if you could be where i'm \n",
      "me none but if i had left and left me and \n",
      "that far to take a stand it's been so long i'm \n"
     ]
    }
   ],
   "source": [
    "song = \"\"\n",
    "\n",
    "for i in range(20):\n",
    "    line_words = generate_sequence(chain, 11)\n",
    "    line = \"\"\n",
    "    \n",
    "    for word in line_words:\n",
    "        line += word + \" \"\n",
    "    \n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
