{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "In this notebook we will explore different machine learning algorithms and try to fit an accurate algorithm to our data so that we can predict future results of NCAA D1 basketball matchups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Data Set\n",
    "Here we will load the data set that was created in the modeling section of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "machine_learning_dataset = pd.read_pickle(\"machine_learning_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wfgp</th>\n",
       "      <th>Wfgp3</th>\n",
       "      <th>Wdr</th>\n",
       "      <th>Wast</th>\n",
       "      <th>Wto</th>\n",
       "      <th>Wpf</th>\n",
       "      <th>Lfgp</th>\n",
       "      <th>Lfgp3</th>\n",
       "      <th>Ldr</th>\n",
       "      <th>Last</th>\n",
       "      <th>Lto</th>\n",
       "      <th>Lpf</th>\n",
       "      <th>Win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46253</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62629</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21495</th>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55532</th>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42770</th>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Wfgp     Wfgp3  Wdr  Wast  Wto  Wpf      Lfgp     Lfgp3  Ldr  Last  \\\n",
       "46253  0.454545  0.312500   26    15   12   16  0.339286  0.066667   22     9   \n",
       "62629  0.420000  0.307692   32    13   19   16  0.338462  0.136364   23     5   \n",
       "21495  0.510638  0.533333   21    19   14   14  0.333333  0.222222   12    11   \n",
       "55532  0.451613  0.333333   25    11    8   23  0.363636  0.250000   29    11   \n",
       "42770  0.480000  0.473684   23    14    9   14  0.500000  0.400000   22    11   \n",
       "\n",
       "       Lto  Lpf   Win  \n",
       "46253   15   23  True  \n",
       "62629   12   19  True  \n",
       "21495   13   25  True  \n",
       "55532   13   15  True  \n",
       "42770   11   19  True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_learning_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(machine_learning_dataset) == 66719\n",
    "assert machine_learning_dataset.isnull().values.any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a New Train/Test Split In The Data\n",
    "In this section we will create another train/test split in the data so that we can analyze the accuracy of different regression models on our data. This time we will not be splitting 50/50 we will instead be splitting 75/25 so that we can test the accuracy of our model while also being able to train the model effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# column setup for the feature columns and target column\n",
    "feature_columns = list(machine_learning_dataset.columns[:-1])\n",
    "target_column = list(machine_learning_dataset.columns[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = machine_learning_dataset[feature_columns]\n",
    "y = machine_learning_dataset[target_column[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = cross_validation.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50039, 12)\n",
      "(50039,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16680, 12)\n",
      "(16680,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing A Machine Learning Model\n",
    "In this section we will explore different machine learning models. Exploring different models will help us determine the correct classifier. Of course in some cases some classifiers are better than others and we would like to get the most accurate classifier for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "The Logistic Regression Classification model was the first model I decided to look at. The model itself takes into account overfitting of the data and also does a very good job analyzing and making predictions about the data. Let's analyze its accuracy on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates our regression model. I chose \"newton-cg\" as the solver mostly because my dataset is fairly large and this solver is supposed to provide performance enhancements. Other variables were tweaked to bring the accuracy of the model up slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model = linear_model.LogisticRegression(solver=\"newton-cg\")\n",
    "logistic_regression_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will measure the accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93201438848920859"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! So there are a few things that could be going on here. That number is unusually high for a predictor. Usually when a number is that high it stems from skewed data. In our case more analysis of the data will be needed to see if this is an accurate score for our logistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "This regression involves using randomly created trees to fit the data. Another bonus about the Random Forest Classifier is that it too, like logistic regression, does a good job at handling overfitting of the data. This classifier uses trees to fit various random sub-samples of the data to increase accuracy and stop overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through analysis of the classifier the more trees that are added as estimators the more accurate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = ensemble.RandomForestClassifier(n_estimators=50)\n",
    "forest_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90587529976019188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is also very accurate just as Logistic Regression is. Again this could be because of the correlation between the data. Weight analysis of features may be used later to analyze this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "This model uses what are called decision trees to fit data. This involves creating \"if-statements\" regarding data to be able to make accurate predictions about new data. This may not be useful in our model just because of the correlation between features in our data. Some features dominate our data and thus could create biased decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_model = tree.DecisionTreeClassifier()\n",
    "decision_tree_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83842925659472423"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty accurate model. Let's analyze more and see what we can find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Classifier\n",
    "This classifier works with binary data and could be used to classify our data depending on its accuracy. Unfortunately I do not think that it fits our continuous features and may not be able to distinguish a difference among features that correlate to our T/F winning target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli_model = naive_bayes.BernoulliNB()\n",
    "bernoulli_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50125899280575537"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulli_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is not very accurate at all. Considering that the dataset I am using has a target classification that is True 50% of the time and False 50% of the time in the data, this model does not do any better trying to help us identify team matchups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Classifier\n",
    "The Gaussian classifier assumes that the likelihood of the features is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_model = naive_bayes.GaussianNB()\n",
    "gaussian_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87410071942446044"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly this model is fairly accurate. Let's analyze another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors Classifier\n",
    "This classifier works through a voting procedure. It takes the \"K\" nearest datasets to the dataset that is trying to be predicted and evaluates on a voting system which classification to give the object to be predicted. This model is probably very accurate and can be tuned given different values of \"K\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=15)\n",
    "knn_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89754196642685846"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more neighbors I give the classifier the more accurate the model becomes. Also a fairly accurate model comparatively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create And Use Our Prediction Function\n",
    "Now that we have some models that can predict games lets compare them! Let's create a prediction function for each model and compare the predictions that are made from each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ncaa_helper as nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teams = pd.read_pickle(\"teams\")\n",
    "season_data_2016 = pd.read_pickle(\"new_season_detailed_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_season_data = nh.calc_year_data(2016, season_data_2016, teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>wp</th>\n",
       "      <th>ppg</th>\n",
       "      <th>fgp</th>\n",
       "      <th>ftp</th>\n",
       "      <th>fgp3</th>\n",
       "      <th>or</th>\n",
       "      <th>dr</th>\n",
       "      <th>ast</th>\n",
       "      <th>to</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>Cal Poly SLO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>71.964286</td>\n",
       "      <td>0.413341</td>\n",
       "      <td>0.681895</td>\n",
       "      <td>0.35443</td>\n",
       "      <td>6.107143</td>\n",
       "      <td>15.357143</td>\n",
       "      <td>13.857143</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team_Name  Season        wp        ppg       fgp       ftp  \\\n",
       "Team_Id                                                                  \n",
       "1142     Cal Poly SLO    2016  0.285714  71.964286  0.413341  0.681895   \n",
       "\n",
       "            fgp3        or         dr        ast         to       stl  \\\n",
       "Team_Id                                                                 \n",
       "1142     0.35443  6.107143  15.357143  13.857143  10.428571  2.714286   \n",
       "\n",
       "              blk     pf  \n",
       "Team_Id                   \n",
       "1142     3.214286  20.75  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_season_data[team_season_data.Team_Name == \"Cal Poly SLO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Prediction Function\n",
    "The following function is a copy of what is in the **ncaa_helper.py** file. This function takes in a classification model, two team names, and the seasonal data for the year we would like to analyze and outputs the probabilities that each team will win the respective matchup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function is not used here in this notebook!!!\n",
    "def predict_game_outcome(team1, team2, season_data, model):\n",
    "    output = \"\"\n",
    "    feature_cols = nh.feature_columns\n",
    "    \n",
    "    team1_stats = list(map(list, season_data[season_data.Team_Name == team1][feature_cols].values))\n",
    "    team2_stats = list(map(list, season_data[season_data.Team_Name == team2][feature_cols].values))\n",
    "    \n",
    "    if len(team1_stats) == 0 or len(team2_stats) == 0:\n",
    "        return \"Error: One of the teams you entered does not exist\"\n",
    "    \n",
    "    team1_stats = team1_stats[0]\n",
    "    team2_stats = team2_stats[0]\n",
    "    \n",
    "    probs = model.predict_proba([team1_stats + team2_stats])\n",
    "    output += \"There is a \" + str(probs[0][1] * 100) + \"% chance that \" + team1 + \" will win this game.\\n\"\n",
    "    output += \"There is a \" + str(probs[0][0] * 100) + \"% chance that \" + team2 + \" will win this game.\\n\" \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing The Function\n",
    "In this section we will be testing the prediction function to see some potential matchups among teams this year using a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 23.5924902075% chance that Cal Poly SLO will win this game.\n",
      "There is a 76.4075097925% chance that Air Force will win this game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nh.predict_game_outcome(\"Cal Poly SLO\", \"Air Force\", team_season_data, logistic_regression_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 36.0% chance that Cal Poly SLO will win this game.\n",
      "There is a 64.0% chance that Air Force will win this game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nh.predict_game_outcome(\"Cal Poly SLO\", \"Air Force\", team_season_data, forest_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 100.0% chance that Cal Poly SLO will win this game.\n",
      "There is a 0.0% chance that Air Force will win this game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nh.predict_game_outcome(\"Cal Poly SLO\", \"Air Force\", team_season_data, decision_tree_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 49.9406212572% chance that Cal Poly SLO will win this game.\n",
      "There is a 50.0593787428% chance that Air Force will win this game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nh.predict_game_outcome(\"Cal Poly SLO\", \"Air Force\", team_season_data, bernoulli_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 27.0824493178% chance that Cal Poly SLO will win this game.\n",
      "There is a 72.9175506822% chance that Air Force will win this game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nh.predict_game_outcome(\"Cal Poly SLO\", \"Air Force\", team_season_data, gaussian_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 20.0% chance that Cal Poly SLO will win this game.\n",
      "There is a 80.0% chance that Air Force will win this game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nh.predict_game_outcome(\"Cal Poly SLO\", \"Air Force\", team_season_data, knn_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through analysis of the outcomes of predicting matchups between teams for Cal Poly and Air Force it is apparent that at least in the case of the decision tree model and the bernoulli model the results are obviously skewed.\n",
    "\n",
    "The other models are around the same accuracy with one another and the Gaussian and Logistic models seem to have the most exact answers whereas the other models seem to round the prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
